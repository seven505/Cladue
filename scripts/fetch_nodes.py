import os
import json
import requests
import base64
import hashlib

def fetch_subscription(url):
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()

        content = response.text.strip()
        try:
            decoded = base64.b64decode(content).decode('utf-8')
            content = decoded
        except:
            pass

        links = [line.strip() for line in content.split('\n')
                 if line.strip() and any(line.startswith(p) for p in ['vmess://', 'vless://', 'trojan://', 'ss://'])]

        print(f"ä» {url[:50]}... è·å–åˆ° {len(links)} ä¸ªèŠ‚ç‚¹")
        return links
    except Exception as e:
        print(f"è·å–è®¢é˜…å¤±è´¥ {url}: {e}")
        return []

def parse_vmess(url):
    import json
    try:
        data = json.loads(base64.b64decode(url[8:]).decode('utf-8'))
        return {
            'protocol': 'vmess',
            'name': data.get('ps', ''),
            'server': data.get('add', ''),
            'port': int(data.get('port', 443)),
            'uuid': data.get('id', ''),
            'method': data.get('scy', 'auto'),
            'network': data.get('net', 'tcp'),
            'path': data.get('path', ''),
            'host': data.get('host', ''),
            'tls': data.get('tls', ''),
            'raw_url': url
        }
    except:
        return None

def parse_node(url):
    if url.startswith('vmess://'):
        return parse_vmess(url)
    # TODO: å…¶ä»–åè®®è§£æï¼Œå¯ç»§ç»­è¡¥å……
    return None

def detect_country(server, name):
    text = (server + ' ' + name).lower()
    countries = {
        'HK': ['hk', 'hong-kong', 'hongkong', 'é¦™æ¸¯'],
        'TW': ['tw', 'taiwan', 'taipei', 'å°æ¹¾'],
        'US': ['us', 'usa', 'america', 'united-states'],
        'JP': ['jp', 'japan', 'tokyo', 'æ—¥æœ¬'],
        'SG': ['sg', 'singapore', 'æ–°åŠ å¡'],
        'KR': ['kr', 'korea', 'seoul', 'éŸ©å›½']
    }
    for code, keywords in countries.items():
        if any(k in text for k in keywords):
            return code
    return 'UN'

def main():
    env_subs = os.environ.get('SUBSCRIPTION_URLS', '')
    if not env_subs:
        print("âŒ æœªé…ç½®è®¢é˜…é“¾æ¥")
        exit(1)

    subscription_urls = [url.strip() for url in env_subs.split(',') if url.strip()]
    print(f"ğŸ“‹ é…ç½®äº† {len(subscription_urls)} ä¸ªè®¢é˜…æº")

    all_links = []
    for url in subscription_urls:
        links = fetch_subscription(url)
        all_links.extend(links)

    print(f"ğŸ“Š æ€»å…±è·å– {len(all_links)} ä¸ªåŸå§‹èŠ‚ç‚¹")

    nodes = []
    for url in all_links:
        node = parse_node(url)
        if node and node['server'] and node['port']:
            node['country'] = detect_country(node['server'], node['name'])
            hash_str = f"{node['server']}:{node['port']}:{node['uuid']}"
            node['hash'] = hashlib.md5(hash_str.encode()).hexdigest()
            nodes.append(node)

    seen_hashes = set()
    unique_nodes = []
    for node in nodes:
        if node['hash'] not in seen_hashes:
            seen_hashes.add(node['hash'])
            unique_nodes.append(node)

    print(f"âœ… è§£æå¹¶å»é‡åå¾—åˆ° {len(unique_nodes)} ä¸ªæœ‰æ•ˆèŠ‚ç‚¹")

    max_test = int(os.environ.get('INPUT_MAX_NODES', '50'))
    if len(unique_nodes) > max_test:
        priority = {'HK': 1, 'TW': 2, 'SG': 3, 'JP': 4, 'KR': 5, 'US': 6}
        unique_nodes.sort(key=lambda x: priority.get(x['country'], 99))
        unique_nodes = unique_nodes[:max_test]
        print(f"ğŸ“Š é™åˆ¶æµ‹è¯•èŠ‚ç‚¹æ•°é‡ä¸º {max_test}")

    with open('raw_nodes.json', 'w', encoding='utf-8') as f:
        json.dump(unique_nodes, f, ensure_ascii=False, indent=2)

    print("âœ… èŠ‚ç‚¹è·å–å®Œæˆï¼Œå‡†å¤‡è¿›è¡Œæµ‹è¯•")

if __name__ == "__main__":
    main()
