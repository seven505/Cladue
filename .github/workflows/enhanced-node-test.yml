# .github/workflows/enhanced-node-test.yml
# å¢å¼ºç‰ˆèŠ‚ç‚¹æµ‹è¯•å·¥ä½œæµï¼Œæ”¯æŒæµ‹é€Ÿå’Œæµåª’ä½“è§£é”æ£€æµ‹

name: ğŸš€ Enhanced Node Testing & Update

on:
  # å®šæ—¶è¿è¡Œ - æ¯4å°æ—¶ï¼ˆæµ‹è¯•è¾ƒè€—æ—¶ï¼‰
  schedule:
    - cron: '0 */4 * * *'  # æ¯4å°æ—¶è¿è¡Œä¸€æ¬¡
    # - cron: '0 6,14,22 * * *'  # æ¯å¤©6ç‚¹ã€14ç‚¹ã€22ç‚¹è¿è¡Œ
  
  # æ‰‹åŠ¨è¿è¡Œ
  workflow_dispatch:
    inputs:
      test_mode:
        description: 'æµ‹è¯•æ¨¡å¼'
        required: false
        default: 'full'
        type: choice
        options:
        - 'basic'    # åŸºç¡€è¿é€šæ€§æµ‹è¯•
        - 'speed'    # åŒ…å«é€Ÿåº¦æµ‹è¯•
        - 'full'     # å®Œæ•´æµ‹è¯•ï¼ˆåŒ…å«æµåª’ä½“ï¼‰
      max_nodes:
        description: 'æœ€å¤§æµ‹è¯•èŠ‚ç‚¹æ•°'
        required: false
        default: '50'
        type: string

env:
  TZ: 'Asia/Shanghai'
  PYTHONUNBUFFERED: '1'

jobs:
  # ç¬¬ä¸€ä¸ªä»»åŠ¡ï¼šè·å–å’Œè§£æèŠ‚ç‚¹
  fetch-nodes:
    runs-on: ubuntu-latest
    outputs:
      nodes-count: ${{ steps.parse.outputs.nodes-count }}
      
    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: ğŸ Setup Python Environment
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: ğŸ“¦ Install Dependencies
      run: |
        pip install --upgrade pip
        pip install requests PyYAML aiohttp asyncio

    - name: ğŸ”„ Fetch and Parse Nodes
      id: parse
      env:
        SUBSCRIPTION_URLS: ${{ secrets.SUBSCRIPTION_URLS }}
      run: |
        echo "ğŸ“¡ å¼€å§‹è·å–è®¢é˜…èŠ‚ç‚¹..."
        python3 << 'EOF'
        import os
        import json
        import requests
        import base64
        from urllib.parse import urlparse, parse_qs, unquote
        import re
        import hashlib
        
        def fetch_subscription(url):
            """è·å–è®¢é˜…å†…å®¹"""
            try:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
                response = requests.get(url, headers=headers, timeout=15)
                response.raise_for_status()
                
                content = response.text.strip()
                try:
                    decoded = base64.b64decode(content).decode('utf-8')
                    content = decoded
                except:
                    pass
                
                links = [line.strip() for line in content.split('\n') 
                        if line.strip() and any(line.startswith(p) for p in ['vmess://', 'vless://', 'trojan://', 'ss://'])]
                
                print(f"ä» {url[:50]}... è·å–åˆ° {len(links)} ä¸ªèŠ‚ç‚¹")
                return links
            except Exception as e:
                print(f"è·å–è®¢é˜…å¤±è´¥ {url}: {e}")
                return []
        
        def parse_vmess(url):
            """è§£ævmessèŠ‚ç‚¹"""
            try:
                data = json.loads(base64.b64decode(url[8:]).decode('utf-8'))
                return {
                    'protocol': 'vmess',
                    'name': data.get('ps', ''),
                    'server': data.get('add', ''),
                    'port': int(data.get('port', 443)),
                    'uuid': data.get('id', ''),
                    'method': data.get('scy', 'auto'),
                    'network': data.get('net', 'tcp'),
                    'path': data.get('path', ''),
                    'host': data.get('host', ''),
                    'tls': data.get('tls', ''),
                    'raw_url': url
                }
            except:
                return None
        
        def parse_node(url):
            """è§£æèŠ‚ç‚¹é“¾æ¥"""
            if url.startswith('vmess://'):
                return parse_vmess(url)
            # å…¶ä»–åè®®è§£æ...
            return None
        
        def detect_country(server, name):
            """æ£€æµ‹å›½å®¶"""
            text = (server + ' ' + name).lower()
        def detect_country(server, name):
            """æ£€æµ‹å›½å®¶"""
            text = (server + ' ' + name).lower()
            countries = {
                'HK': ['hk', 'hong-kong', 'hongkong', 'é¦™æ¸¯'],
                'TW': ['tw', 'taiwan', 'taipei', 'å°æ¹¾'],
                'US': ['us', 'usa', 'america', 'united-states'],
                'JP': ['jp', 'japan', 'tokyo', 'æ—¥æœ¬'],
                'SG': ['sg', 'singapore', 'æ–°åŠ å¡'],
                'KR': ['kr', 'korea', 'seoul', 'éŸ©å›½']
            }
            
            for code, keywords in countries.items():
                if any(k in text for k in keywords):
                    return code
            return 'UN'
        
        # ä¸»ç¨‹åº
        env_subs = os.environ.get('SUBSCRIPTION_URLS', '')
        if not env_subs:
            print("âŒ æœªé…ç½®è®¢é˜…é“¾æ¥")
            exit(1)
        
        subscription_urls = [url.strip() for url in env_subs.split(',') if url.strip()]
        print(f"ğŸ“‹ é…ç½®äº† {len(subscription_urls)} ä¸ªè®¢é˜…æº")
        
        all_links = []
        for url in subscription_urls:
            links = fetch_subscription(url)
            all_links.extend(links)
        
        print(f"ğŸ“Š æ€»å…±è·å– {len(all_links)} ä¸ªåŸå§‹èŠ‚ç‚¹")
        
        # è§£æèŠ‚ç‚¹
        nodes = []
        for url in all_links:
            node = parse_node(url)
            if node and node['server'] and node['port']:
                node['country'] = detect_country(node['server'], node['name'])
                # å»é‡å“ˆå¸Œ
                hash_str = f"{node['server']}:{node['port']}:{node['uuid']}"
                node['hash'] = hashlib.md5(hash_str.encode()).hexdigest()
                nodes.append(node)
        
        # å»é‡
        seen_hashes = set()
        unique_nodes = []
        for node in nodes:
            if node['hash'] not in seen_hashes:
                seen_hashes.add(node['hash'])
                unique_nodes.append(node)
        
        print(f"âœ… è§£æå¹¶å»é‡åå¾—åˆ° {len(unique_nodes)} ä¸ªæœ‰æ•ˆèŠ‚ç‚¹")
        
        # é™åˆ¶æµ‹è¯•æ•°é‡ï¼ˆæµ‹è¯•è€—æ—¶è¾ƒé•¿ï¼‰
        max_test = int(os.environ.get('INPUT_MAX_NODES', '50'))
        if len(unique_nodes) > max_test:
            # æŒ‰å›½å®¶ä¼˜å…ˆçº§æ’åºï¼Œä¼˜å…ˆæµ‹è¯•äºšæ´²èŠ‚ç‚¹
            priority = {'HK': 1, 'TW': 2, 'SG': 3, 'JP': 4, 'KR': 5, 'US': 6}
            unique_nodes.sort(key=lambda x: priority.get(x['country'], 99))
            unique_nodes = unique_nodes[:max_test]
            print(f"ğŸ“Š é™åˆ¶æµ‹è¯•èŠ‚ç‚¹æ•°é‡ä¸º {max_test}")
        
        # ä¿å­˜èŠ‚ç‚¹æ•°æ®
        with open('raw_nodes.json', 'w', encoding='utf-8') as f:
            json.dump(unique_nodes, f, ensure_ascii=False, indent=2)
        
        print(f"::set-output name=nodes-count::{len(unique_nodes)}")
        print(f"âœ… èŠ‚ç‚¹è·å–å®Œæˆï¼Œå‡†å¤‡è¿›è¡Œæµ‹è¯•")
        EOF

    - name: ğŸ“¤ Upload Raw Nodes
      uses: actions/upload-artifact@v3
      with:
        name: raw-nodes
        path: raw_nodes.json

  # ç¬¬äºŒä¸ªä»»åŠ¡ï¼šèŠ‚ç‚¹è¿é€šæ€§å’Œé€Ÿåº¦æµ‹è¯•
  test-nodes:
    runs-on: ubuntu-latest
    needs: fetch-nodes
    if: needs.fetch-nodes.outputs.nodes-count > 0
    
    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4

    - name: ğŸ Setup Python Environment
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: ğŸ“¦ Install Enhanced Dependencies
      run: |
        pip install --upgrade pip
        pip install aiohttp asyncio requests PyYAML
        # å®‰è£…é¢å¤–çš„ç½‘ç»œæµ‹è¯•å·¥å…·
        sudo apt-get update
        sudo apt-get install -y curl wget netcat-openbsd

    - name: ğŸ“¥ Download Raw Nodes
      uses: actions/download-artifact@v3
      with:
        name: raw-nodes

    - name: ğŸ§ª Enhanced Node Testing
      env:
        TEST_MODE: ${{ github.event.inputs.test_mode || 'full' }}
      run: |
        echo "ğŸ§ª å¼€å§‹å¢å¼ºç‰ˆèŠ‚ç‚¹æµ‹è¯•..."
        echo "æµ‹è¯•æ¨¡å¼: $TEST_MODE"
        
        python3 << 'EOF'
        import asyncio
        import aiohttp
        import json
        import time
        import socket
        import os
        import subprocess
        from concurrent.futures import ThreadPoolExecutor
        
        async def tcp_ping_test(host, port, timeout=5):
            """TCPè¿æ¥æµ‹è¯•"""
            try:
                start_time = time.time()
                _, writer = await asyncio.wait_for(
                    asyncio.open_connection(host, port),
                    timeout=timeout
                )
                ping_time = (time.time() - start_time) * 1000
                writer.close()
                await writer.wait_closed()
                return True, ping_time
            except:
                return False, -1
        
        async def http_speed_test(session, test_url="http://www.gstatic.com/generate_204"):
            """HTTPé€Ÿåº¦æµ‹è¯•"""
            try:
                start_time = time.time()
                async with session.get(test_url, timeout=aiohttp.ClientTimeout(total=10)) as response:
                    await response.read()
                    return (time.time() - start_time) * 1000
            except:
                return -1
        
        async def download_speed_test(session, size_mb=1):
            """ä¸‹è½½é€Ÿåº¦æµ‹è¯•"""
            try:
                # ä½¿ç”¨å°æ–‡ä»¶æµ‹è¯•ï¼Œé¿å…GitHub Actionsè¶…æ—¶
                test_url = "https://proof.ovh.net/files/1Mb.dat"
                start_time = time.time()
                
                async with session.get(test_url, timeout=aiohttp.ClientTimeout(total=15)) as response:
                    if response.status == 200:
                        downloaded = 0
                        async for chunk in response.content.iter_chunked(8192):
                            downloaded += len(chunk)
                            # é™åˆ¶æµ‹è¯•æ—¶é—´
                            if time.time() - start_time > 10:
                                break
                        
                        elapsed = time.time() - start_time
                        if elapsed > 0:
                            speed_mbps = (downloaded / 1024 / 1024) / elapsed
                            return speed_mbps
                return 0
            except:
                return 0
        
        async def get_ip_info(session):
            """è·å–IPä¿¡æ¯"""
            try:
                async with session.get("https://httpbin.org/ip", 
                                     timeout=aiohttp.ClientTimeout(total=10)) as response:
                    if response.status == 200:
                        data = await response.json()
                        return data.get("origin", "æœªçŸ¥")
                return "æœªçŸ¥"
            except:
                return "æ£€æµ‹å¤±è´¥"
        
        async def test_streaming_unlock(session):
            """æµåª’ä½“è§£é”æµ‹è¯•ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
            results = {}
            
            # Netflixæµ‹è¯•
            try:
                async with session.get("https://www.netflix.com/", 
                                     timeout=aiohttp.ClientTimeout(total=10)) as response:
                    if response.status == 200:
                        content = await response.text()
                        if "Not Available" in content:
                            results['netflix'] = "âŒ ä¸æ”¯æŒ"
                        else:
                            results['netflix'] = "âœ… å¯èƒ½æ”¯æŒ"
                    else:
                        results['netflix'] = "â“ æ£€æµ‹å¤±è´¥"
            except:
                results['netflix'] = "â“ è¶…æ—¶"
            
            # YouTubeæµ‹è¯•
            try:
                async with session.get("https://www.youtube.com/", 
                                     timeout=aiohttp.ClientTimeout(total=10)) as response:
                    if response.status == 200:
                        results['youtube'] = "âœ… å¯è®¿é—®"
                    else:
                        results['youtube'] = "âŒ æ— æ³•è®¿é—®"
            except:
                results['youtube'] = "â“ è¶…æ—¶"
            
            return results
        
        async def test_single_node(node, test_mode):
            """æµ‹è¯•å•ä¸ªèŠ‚ç‚¹"""
            result = {
                'name': node['name'],
                'server': node['server'],
                'port': node['port'],
                'protocol': node['protocol'],
                'country': node['country'],
                'is_alive': False,
                'tcp_ping': -1,
                'http_ping': -1,
                'download_speed': 0,
                'ip_info': 'æœªçŸ¥',
                'streaming': {},
                'test_time': time.strftime('%Y-%m-%d %H:%M:%S'),
                'error': ''
            }
            
            try:
                print(f"ğŸ§ª æµ‹è¯•èŠ‚ç‚¹: {node['name']}")
                
                # 1. TCPè¿æ¥æµ‹è¯•
                is_alive, tcp_ping = await tcp_ping_test(node['server'], node['port'])
                result['is_alive'] = is_alive
                result['tcp_ping'] = tcp_ping
                
                if not is_alive:
                    result['error'] = 'TCPè¿æ¥å¤±è´¥'
                    return result
                
                # 2. HTTPæµ‹è¯•ï¼ˆå¦‚æœèŠ‚ç‚¹å­˜æ´»ï¼‰
                connector = aiohttp.TCPConnector(limit=1, ttl_dns_cache=300)
                async with aiohttp.ClientSession(connector=connector) as session:
                    
                    if test_mode in ['speed', 'full']:
                        # HTTPå»¶è¿Ÿæµ‹è¯•
                        result['http_ping'] = await http_speed_test(session)
                        
                        # ä¸‹è½½é€Ÿåº¦æµ‹è¯•
                        result['download_speed'] = await download_speed_test(session)
                    
                    if test_mode == 'full':
                        # IPä¿¡æ¯è·å–
                        result['ip_info'] = await get_ip_info(session)
                        
                        # æµåª’ä½“è§£é”æµ‹è¯•
                        result['streaming'] = await test_streaming_unlock(session)
                
                print(f"âœ… èŠ‚ç‚¹ {node['name']} æµ‹è¯•å®Œæˆ")
                
            except Exception as e:
                result['error'] = str(e)
                print(f"âŒ èŠ‚ç‚¹ {node['name']} æµ‹è¯•å¤±è´¥: {e}")
            
            return result
        
        async def main():
            # è¯»å–èŠ‚ç‚¹æ•°æ®
            with open('raw_nodes.json', 'r', encoding='utf-8') as f:
                nodes = json.load(f)
            
            test_mode = os.environ.get('TEST_MODE', 'full')
            print(f"ğŸ“Š å¼€å§‹æµ‹è¯• {len(nodes)} ä¸ªèŠ‚ç‚¹ï¼Œæ¨¡å¼: {test_mode}")
            
            # é™åˆ¶å¹¶å‘æ•°ï¼Œé¿å…è¢«å°IP
            semaphore = asyncio.Semaphore(3)
            
            async def test_with_limit(node):
                async with semaphore:
                    return await test_single_node(node, test_mode)
            
            # æ‰§è¡Œæµ‹è¯•
            start_time = time.time()
            results = await asyncio.gather(*[test_with_limit(node) for node in nodes])
            elapsed = time.time() - start_time
            
            print(f"ğŸ“Š æµ‹è¯•å®Œæˆï¼Œè€—æ—¶ {elapsed:.2f} ç§’")
            
            # ç»Ÿè®¡ç»“æœ
            alive_nodes = [r for r in results if r['is_alive']]
            dead_nodes = [r for r in results if not r['is_alive']]
            
            stats = {
                'test_time': time.strftime('%Y-%m-%d %H:%M:%S'),
                'test_mode': test_mode,
                'total_nodes': len(results),
                'alive_nodes': len(alive_nodes),
                'dead_nodes': len(dead_nodes),
                'success_rate': len(alive_nodes) / len(results) * 100 if results else 0,
                'avg_tcp_ping': sum(r['tcp_ping'] for r in alive_nodes if r['tcp_ping'] > 0) / len(alive_nodes) if alive_nodes else 0,
                'avg_download_speed': sum(r['download_speed'] for r in alive_nodes) / len(alive_nodes) if alive_nodes else 0
            }
            
            # åœ°åŒºç»Ÿè®¡
            country_stats = {}
            for result in alive_nodes:
                country = result['country']
                if country not in country_stats:
                    country_stats[country] = {'total': 0, 'avg_ping': 0, 'avg_speed': 0}
                country_stats[country]['total'] += 1
            
            # ä¿å­˜è¯¦ç»†ç»“æœ
            test_report = {
                'stats': stats,
                'country_stats': country_stats,
                'results': results
            }
            
            with open('test_results.json', 'w', encoding='utf-8') as f:
                json.dump(test_report, f, ensure_ascii=False, indent=2)
            
            # ç”Ÿæˆå¯ç”¨èŠ‚ç‚¹åˆ—è¡¨
            working_nodes = [r for r in results if r['is_alive'] and r['tcp_ping'] < 1000]
            working_nodes.sort(key=lambda x: x['tcp_ping'])
            
            print(f"ğŸ“Š æµ‹è¯•ç»Ÿè®¡:")
            print(f"  æ€»èŠ‚ç‚¹æ•°: {stats['total_nodes']}")
            print(f"  å¯ç”¨èŠ‚ç‚¹: {stats['alive_nodes']}")
            print(f"  æˆåŠŸç‡: {stats['success_rate']:.1f}%")
            print(f"  å¹³å‡å»¶è¿Ÿ: {stats['avg_tcp_ping']:.1f}ms")
            print(f"  å¹³å‡é€Ÿåº¦: {stats['avg_download_speed']:.2f}MB/s")
            
            # è¾“å‡ºæœ€ä½³èŠ‚ç‚¹
            if working_nodes:
                print(f"\nğŸ† æœ€ä½³èŠ‚ç‚¹ TOP 5:")
                for i, node in enumerate(working_nodes[:5], 1):
                    print(f"  {i}. {node['name']} - {node['tcp_ping']:.1f}ms")
        
        # è¿è¡Œæµ‹è¯•
        asyncio.run(main())
        EOF

    - name: ğŸ“¤ Upload Test Results
      uses: actions/upload-artifact@v3
      with:
        name: test-results
        path: test_results.json

  # ç¬¬ä¸‰ä¸ªä»»åŠ¡ï¼šç”Ÿæˆé…ç½®æ–‡ä»¶å’Œéƒ¨ç½²
  generate-configs:
    runs-on: ubuntu-latest
    needs: [fetch-nodes, test-nodes]
    
    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4

    - name: ğŸ Setup Python Environment
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: ğŸ“¥ Download Test Results
      uses: actions/download-artifact@v3
      with:
        name: test-results

    - name: ğŸ“¥ Download Raw Nodes
      uses: actions/download-artifact@v3
      with:
        name: raw-nodes

    - name: ğŸ”§ Generate Enhanced Configs
      run: |
        echo "ğŸ”§ ç”Ÿæˆå¢å¼ºç‰ˆé…ç½®æ–‡ä»¶..."
        
        python3 << 'EOF'
        import json
        import base64
        import time
        
        # è¯»å–æµ‹è¯•ç»“æœ
        with open('test_results.json', 'r', encoding='utf-8') as f:
            test_data = json.load(f)
        
        with open('raw_nodes.json', 'r', encoding='utf-8') as f:
            raw_nodes = json.load(f)
        
        results = test_data['results']
        stats = test_data['stats']
        
        # è¿‡æ»¤å¯ç”¨èŠ‚ç‚¹
        working_nodes = []
        for result in results:
            if result['is_alive'] and result['tcp_ping'] > 0 and result['tcp_ping'] < 2000:
                # æ‰¾åˆ°å¯¹åº”çš„åŸå§‹èŠ‚ç‚¹æ•°æ®
                for raw_node in raw_nodes:
                    if (raw_node['server'] == result['server'] and 
                        raw_node['port'] == result['port']):
                        enhanced_node = raw_node.copy()
                        enhanced_node.update({
                            'test_result': result,
                            'enhanced_name': f"[{result['tcp_ping']:.0f}ms] {result['name']}"
                        })
                        working_nodes.append(enhanced_node)
                        break
        
        # æŒ‰å»¶è¿Ÿæ’åº
        working_nodes.sort(key=lambda x: x['test_result']['tcp_ping'])
        
        print(f"ğŸ“Š ç”Ÿæˆé…ç½®ï¼ŒåŒ…å« {len(working_nodes)} ä¸ªä¼˜è´¨èŠ‚ç‚¹")
        
        # ç”ŸæˆClashé…ç½®
        def generate_clash_config(nodes):
            proxies = []
            proxy_names = []
            
            for node in nodes:
                name = node['enhanced_name']
                proxy_names.append(name)
                
                if node['protocol'] == 'vmess':
                    proxy = {
                        'name': name,
                        'type': 'vmess',
                        'server': node['server'],
                        'port': node['port'],
                        'uuid': node['uuid'],
                        'alterId': 0,
                        'cipher': node.get('method', 'auto'),
                        'network': node.get('network', 'tcp'),
                        'udp': True
                    }
                    
                    if node.get('tls'):
                        proxy['tls'] = True
                    if node.get('host'):
                        proxy['servername'] = node['host']
                    if node.get('path') and node.get('network') == 'ws':
                        proxy['ws-opts'] = {'path': node['path']}
                        if node.get('host'):
                            proxy['ws-opts']['headers'] = {'Host': node['host']}
                
                proxies.append(proxy)
            
            # æŒ‰åœ°åŒºåˆ†ç»„
            country_groups = {}
            for node in nodes:
                country = node['country']
                if country not in country_groups:
                    country_groups[country] = []
                country_groups[country].append(node['enhanced_name'])
            
            proxy_groups = [
                {
                    'name': 'ğŸš€ èŠ‚ç‚¹é€‰æ‹©',
                    'type': 'select',
                    'proxies': ['â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'ğŸ”¯ æ•…éšœè½¬ç§»'] + proxy_names[:10]
                },
                {
                    'name': 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©',
                    'type': 'url-test',
                    'proxies': proxy_names,
                    'url': 'http://www.gstatic.com/generate_204',
                    'interval': 300,
                    'tolerance': 50
                },
                {
                    'name': 'ğŸ”¯ æ•…éšœè½¬ç§»',
                    'type': 'fallback',
                    'proxies': proxy_names,
                    'url': 'http://www.gstatic.com/generate_204',
                    'interval': 300
                }
            ]
            
            # æ·»åŠ åœ°åŒºåˆ†ç»„
            region_names = {
                'HK': 'ğŸ‡­ğŸ‡°é¦™æ¸¯èŠ‚ç‚¹', 'TW': 'ğŸ‡¹ğŸ‡¼å°æ¹¾èŠ‚ç‚¹', 'US': 'ğŸ‡ºğŸ‡¸ç¾å›½èŠ‚ç‚¹',
                'JP': 'ğŸ‡¯ğŸ‡µæ—¥æœ¬èŠ‚ç‚¹', 'SG': 'ğŸ‡¸ğŸ‡¬æ–°åŠ å¡èŠ‚ç‚¹', 'KR': 'ğŸ‡°ğŸ‡·éŸ©å›½èŠ‚ç‚¹'
            }
            
            for country, nodes_list in country_groups.items():
                if len(nodes_list) >= 2:
                    group_name = region_names.get(country, f'{country}èŠ‚ç‚¹')
                    proxy_groups.append({
                        'name': group_name,
                        'type': 'select',
                        'proxies': ['â™»ï¸ è‡ªåŠ¨é€‰æ‹©'] + nodes_list
                    })
            
            return {
                'proxies': proxies,
                'proxy-groups': proxy_groups
            }
        
        # ç”ŸæˆV2Rayè®¢é˜…
        def generate_v2ray_subscription(nodes):
            links = [node['raw_url'] for node in nodes if node.get('raw_url')]
            content = '\n'.join(links)
            return base64.b64encode(content.encode('utf-8')).decode('utf-8')
        
        # ç”Ÿæˆå¢å¼ºç»Ÿè®¡æŠ¥å‘Š
        def generate_enhanced_report():
            return {
                'last_update': time.strftime('%Y-%m-%d %H:%M:%S'),
                'test_summary': stats,
                'quality_nodes': len(working_nodes),
                'top_nodes': [
                    {
                        'name': node['name'],
                        'country': node['country'],
                        'ping': f"{node['test_result']['tcp_ping']:.1f}ms",
                        'speed': f"{node['test_result']['download_speed']:.2f}MB/s" if node['test_result']['download_speed'] > 0 else "æœªæµ‹è¯•"
                    }
                    for node in working_nodes[:10]
                ],
                'country_distribution': test_data.get('country_stats', {}),
                'streaming_support': {
                    node['name']: node['test_result'].get('streaming', {})
                    for node in working_nodes[:5] 
                    if node['test_result'].get('streaming')
                }
            }
        
        # ç”Ÿæˆæ‰€æœ‰é…ç½®æ–‡ä»¶
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        
        # Clashé…ç½®
        clash_config = generate_clash_config(working_nodes)
        try:
            import yaml
            clash_content = yaml.dump(clash_config, allow_unicode=True, default_flow_style=False)
        except ImportError:
            clash_content = json.dumps(clash_config, ensure_ascii=False, indent=2)
        
        with open(f'clash_enhanced_{timestamp}.yaml', 'w', encoding='utf-8') as f:
            f.write(clash_content)
        
        # V2Rayè®¢é˜…
        v2ray_content = generate_v2ray_subscription(working_nodes)
        with open(f'v2ray_enhanced_{timestamp}.txt', 'w', encoding='utf-8') as f:
            f.write(v2ray_content)
        
        # å¢å¼ºæŠ¥å‘Š
        report = generate_enhanced_report()
        with open(f'enhanced_report_{timestamp}.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # åˆ›å»ºlatestè½¯é“¾æ¥
        import os
        
        def safe_symlink(src, dst):
            if os.path.exists(dst):
                os.remove(dst)
            os.symlink(src, dst)
        
        safe_symlink(f'clash_enhanced_{timestamp}.yaml', 'clash_latest.yaml')
        safe_symlink(f'v2ray_enhanced_{timestamp}.txt', 'v2ray_latest.txt') 
        safe_symlink(f'enhanced_report_{timestamp}.json', 'report_latest.json')
        
        print(f"âœ… é…ç½®ç”Ÿæˆå®Œæˆ:")
        print(f"  - Clashé…ç½®: clash_enhanced_{timestamp}.yaml")
        print(f"  - V2Rayè®¢é˜…: v2ray_enhanced_{timestamp}.txt")
        print(f"  - å¢å¼ºæŠ¥å‘Š: enhanced_report_{timestamp}.json")
        print(f"  - ä¼˜è´¨èŠ‚ç‚¹æ•°: {len(working_nodes)}")
        EOF

    - name: âš™ï¸ Configure Git
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "Enhanced Node Tester"

    - name: ğŸ§¹ Cleanup Old Files
      run: |
        # ä¿ç•™æœ€è¿‘5ä¸ªç‰ˆæœ¬
        ls -t clash_enhanced_*.yaml | tail -n +6 | xargs -r rm -f
        ls -t v2ray_enhanced_*.txt | tail -n +6 | xargs -r rm -f
        ls -t enhanced_report_*.json | tail -n +6 | xargs -r rm -f

    - name: ğŸ“¤ Commit Enhanced Results
      run: |
        git add *.yaml *.txt *.json || true
        git commit -m "ğŸ¤– Enhanced node test results - $(date '+%Y-%m-%d %H:%M:%S')" || echo "No changes"
        git push || echo "Nothing to push"

    - name: ğŸŒ Deploy to GitHub Pages
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./
        publish_branch: gh-pages
        keep_files: false
        include_files: |
          *_latest.*
          clash_enhanced_*.yaml
          v2ray_enhanced_*.txt
          enhanced_report_*.json

    - name: ğŸ“Š Generate Summary
      run: |
        if [ -f "report_latest.json" ]; then
          echo "## ğŸš€ å¢å¼ºç‰ˆèŠ‚ç‚¹æµ‹è¯•æŠ¥å‘Š" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          python3 << 'EOF' >> $GITHUB_STEP_SUMMARY
        import json
        
        with open('report_latest.json', 'r', encoding='utf-8') as f:
            report = json.load(f)
        
        stats = report['test_summary']
        
        print(f"### ğŸ“ˆ æµ‹è¯•ç»Ÿè®¡")
        print(f"- **æ›´æ–°æ—¶é—´**: {report['last_update']}")
        print(f"- **æ€»èŠ‚ç‚¹æ•°**: {stats['total_nodes']}")
        print(f"- **å¯ç”¨èŠ‚ç‚¹**: {stats['alive_nodes']}")
        print(f"- **ä¼˜è´¨èŠ‚ç‚¹**: {report['quality_nodes']}")
        print(f"- **æˆåŠŸç‡**: {stats['success_rate']:.1f}%")
        print(f"- **å¹³å‡å»¶è¿Ÿ**: {stats['avg_tcp_ping']:.1f}ms")
        print(f"- **å¹³å‡é€Ÿåº¦**: {stats['avg_download_speed']:.2f}MB/s")
        print()
        
        print("### ğŸ† ä¼˜è´¨èŠ‚ç‚¹ TOP 5")
        for i, node in enumerate(report['top_nodes'][:5], 1):
            print(f"{i}. **{node['name']}** - {node['ping']} - {node['speed']}")
        print()
        
        print("### ğŸ”— è®¢é˜…é“¾æ¥")
        repo_url = "https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}"
        print(f"- **Clashå¢å¼ºç‰ˆ**: {repo_url}/clash_latest.yaml")
        print(f"- **V2Rayå¢å¼ºç‰ˆ**: {repo_url}/v2ray_latest.txt")
        print(f"- **è¯¦ç»†æŠ¥å‘Š**: {repo_url}/report_latest.json")
        EOF
        fi

    - name: ğŸ“¢ Send Notification
      if: always()
      env:
        WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
      run: |
        if [ ! -z "$WEBHOOK_URL" ]; then
          STATUS_EMOJI="âœ…"
          if [ "${{ job.status }}" != "success" ]; then
            STATUS_EMOJI="âŒ"
          fi
          
          QUALITY_NODES="0"
          if [ -f "report_latest.json" ]; then
            QUALITY_NODES=$(python3 -c "import json; print(json.load(open('report_latest.json'))['quality_nodes'])")
          fi
          
          MESSAGE="$STATUS_EMOJI å¢å¼ºç‰ˆèŠ‚ç‚¹æµ‹è¯•å®Œæˆ
          
ğŸ“Š æµ‹è¯•ç»“æœ: ${{ needs.test-nodes.result }}
ğŸ† ä¼˜è´¨èŠ‚ç‚¹: $QUALITY_NODES ä¸ª
â° æµ‹è¯•æ—¶é—´: $(date '+%Y-%m-%d %H:%M:%S')
ğŸ”— ä»“åº“: ${{ github.repository }}
ğŸ¯ è¿è¡ŒID: ${{ github.run_id }}"
          
          curl -X POST "$WEBHOOK_URL" \
            -H "Content-Type: application/json" \
            -d "{\"text\": \"$MESSAGE\"}"
        fi
                '
